{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# 数据预处理\n\n数据预处理是机器学习过程中非常重要的一步。在这一部分，我们将介绍数据预处理的几个关键步骤，并通过实际代码示例来演示每个步骤的实现方法。"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 导入必要的库\n\n在开始数据预处理之前，我们需要导入一些常用的库。"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "import numpy as np\nimport pandas as pd\nfrom sklearn.preprocessing import StandardScaler, MinMaxScaler, OneHotEncoder\nfrom sklearn.impute import SimpleImputer",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 处理缺失值\n\n在数据集中，缺失值是一个常见的问题。我们可以使用多种方法来处理缺失值，包括删除包含缺失值的样本，或用其他值（如均值或中位数）填补缺失值。"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "# 创建一个示例数据集\ndata = {'A': [1, 2, np.nan, 4], 'B': [5, np.nan, np.nan, 8], 'C': [10, 11, 12, 13]}\ndf = pd.DataFrame(data)\nprint(\"原始数据:\")\nprint(df)\n\n# 使用均值填补缺失值\nimputer = SimpleImputer(strategy='mean')\ndf_imputed = pd.DataFrame(imputer.fit_transform(df), columns=df.columns)\nprint(\"\\n填补缺失值后的数据:\")\nprint(df_imputed)",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 数据规范化\n\n数据规范化是将不同量纲的数据转换到同一量纲上，以避免某些特征对模型的影响过大。常见的规范化方法有标准化（Standardization）和归一化（Normalization）。"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "# 创建一个示例数据集\ndata = {'A': [1, 2, 3, 4], 'B': [100, 200, 300, 400]}\ndf = pd.DataFrame(data)\nprint(\"原始数据:\")\nprint(df)\n\n# 标准化数据\nscaler = StandardScaler()\ndf_standardized = pd.DataFrame(scaler.fit_transform(df), columns=df.columns)\nprint(\"\\n标准化后的数据:\")\nprint(df_standardized)\n\n# 归一化数据\nscaler = MinMaxScaler()\ndf_normalized = pd.DataFrame(scaler.fit_transform(df), columns=df.columns)\nprint(\"\\n归一化后的数据:\")\nprint(df_normalized)",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 特征提取与选择\n\n特征提取是指从原始数据中提取有用的信息，转换为模型可以处理的特征。特征选择是从众多特征中选择对模型预测最有帮助的特征。"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "# 创建一个示例数据集\ndata = {'A': [1, 2, 3, 4], 'B': [100, 200, 300, 400], 'C': ['red', 'green', 'blue', 'yellow']}\ndf = pd.DataFrame(data)\nprint(\"原始数据:\")\nprint(df)\n\n# 使用 OneHotEncoder 对分类数据进行编码\nencoder = OneHotEncoder(sparse_output=False)\nencoded_features = encoder.fit_transform(df[['C']])\nencoded_df = pd.DataFrame(encoded_features, columns=encoder.get_feature_names_out(['C']))\n\n# 将编码后的特征与原数据集连接\ndf_combined = df.drop('C', axis=1).join(encoded_df)\nprint(\"\\n编码后的数据:\")\nprint(df_combined)",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "通过上述步骤，我们可以看到数据预处理的基本流程和方法。在实际的机器学习项目中，数据预处理是至关重要的一步，它直接影响到模型的性能和效果。在接下来的章节中，我们将进一步探讨具体的机器学习算法及其应用。"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

