{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# 数据预处理\n\n数据预处理是机器学习流程中至关重要的一步。它包括处理缺失值、数据标准化和归一化、编码分类变量等步骤。"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 处理缺失值\n\n在数据收集中，可能会遇到缺失值。这些缺失值可能是由于数据收集过程中的错误或遗漏造成的。常见的处理缺失值的方法有删除包含缺失值的样本、用均值或中位数填补缺失值等。"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "import numpy as np\nimport pandas as pd\nfrom sklearn.impute import SimpleImputer\n\n# 创建示例数据集，包含缺失值\ndata = {'A': [1, 2, np.nan, 4], 'B': [5, np.nan, np.nan, 8], 'C': [10, 11, 12, 13]}\ndf = pd.DataFrame(data)\nprint('原始数据:')\nprint(df)\n\n# 使用均值填补缺失值\nimputer = SimpleImputer(strategy='mean')\ndf_imputed = pd.DataFrame(imputer.fit_transform(df), columns=df.columns)\nprint('\\n填补缺失值后的数据:')\nprint(df_imputed)",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 数据标准化和归一化\n\n数据标准化是将数据转换为均值为0，标准差为1的分布。归一化是将数据缩放到[0, 1]区间。标准化和归一化可以加速模型训练并提高模型性能。"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n\n# 创建示例数据集\ndata = {'特征1': [1, 2, 3, 4, 5], '特征2': [5, 4, 3, 2, 1]}\ndf = pd.DataFrame(data)\nprint('原始数据:')\nprint(df)\n\n# 数据标准化\nscaler = StandardScaler()\ndf_standardized = pd.DataFrame(scaler.fit_transform(df), columns=df.columns)\nprint('\\n标准化后的数据:')\nprint(df_standardized)\n\n# 数据归一化\nscaler = MinMaxScaler()\ndf_normalized = pd.DataFrame(scaler.fit_transform(df), columns=df.columns)\nprint('\\n归一化后的数据:')\nprint(df_normalized)",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 编码分类变量\n\n在数据集中，分类变量是指值为类别的变量，如颜色（红、绿、蓝）。机器学习模型通常只能处理数值数据，因此需要将分类变量转换为数值表示。常见的方法有标签编码和独热编码。"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "from sklearn.preprocessing import OneHotEncoder\n\n# 创建示例数据集\ndata = {'颜色': ['红', '绿', '蓝', '绿', '红']}\ndf = pd.DataFrame(data)\nprint('原始数据:')\nprint(df)\n\n# 独热编码\nencoder = OneHotEncoder(sparse_output=False)\nencoded_features = encoder.fit_transform(df[['颜色']])\nencoded_df = pd.DataFrame(encoded_features, columns=encoder.get_feature_names_out(['颜色']))\n\n# 将编码后的特征与原数据集连接\ndf_combined = df.join(encoded_df)\nprint('\\n独热编码后的数据:')\nprint(df_combined)",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "通过上述步骤，我们可以看到数据预处理的基本流程和方法。在实际的机器学习项目中，数据预处理是至关重要的一步，它直接影响到模型的性能和效果。在接下来的章节中，我们将进一步探讨具体的机器学习算法及其应用。"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

