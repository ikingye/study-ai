{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# 循环神经网络（RNN）\n\n循环神经网络是一种擅长处理序列数据的神经网络，通过在时间步之间共享参数，实现对时间序列数据的建模。RNN在语音识别、文本生成、机器翻译等任务中广泛应用。"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## RNN的结构\n\nRNN的基本单元是循环单元（Recurrent Unit），其输出依赖于当前输入和上一个时间步的输出。通过循环单元的堆叠，可以构建深层循环神经网络。"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "import tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import SimpleRNN, Dense\n\n# 构建一个简单的RNN\nmodel = Sequential([\n    SimpleRNN(50, activation='relu', input_shape=(10, 1)),\n    Dense(1)\n])\n\n# 编译模型\nmodel.compile(optimizer='adam', loss='mse')\n\n# 输出模型摘要\nmodel.summary()",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 长短期记忆网络（LSTM）\n\nLSTM是一种改进的RNN，通过引入门控机制（输入门、遗忘门和输出门），解决了传统RNN中的梯度消失和梯度爆炸问题。"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "from tensorflow.keras.layers import LSTM\n\n# 构建一个简单的LSTM\nmodel = Sequential([\n    LSTM(50, activation='relu', input_shape=(10, 1)),\n    Dense(1)\n])\n\n# 编译模型\nmodel.compile(optimizer='adam', loss='mse')\n\n# 输出模型摘要\nmodel.summary()",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 双向RNN\n\n双向RNN通过同时考虑正向和反向的时间序列信息，提高模型的上下文理解能力。在文本生成和机器翻译等任务中，双向RNN表现出色。"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "from tensorflow.keras.layers import Bidirectional\n\n# 构建一个双向LSTM\nmodel = Sequential([\n    Bidirectional(LSTM(50, activation='relu'), input_shape=(10, 1)),\n    Dense(1)\n])\n\n# 编译模型\nmodel.compile(optimizer='adam', loss='mse')\n\n# 输出模型摘要\nmodel.summary()",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## RNN的应用\n\nRNN在序列预测、语音识别、文本生成等任务中广泛应用。以下是一个使用LSTM进行时间序列预测的示例。"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "import numpy as np\n\n# 生成示例数据\nx = np.linspace(0, 100, 1000)\ny = np.sin(x)\n\n# 构建训练数据\ndef create_dataset(x, y, time_steps=10):\n    Xs, ys = [], []\n    for i in range(len(x) - time_steps):\n        Xs.append(x[i:(i + time_steps)])\n        ys.append(y[i + time_steps])\n    return np.array(Xs), np.array(ys)\n\nX, y = create_dataset(x, y)\nX = X.reshape(-1, 10, 1)\n\n# 训练模型\nmodel.fit(X, y, epochs=10, batch_size=32)\n\n# 预测\ny_pred = model.predict(X)\n\n# 绘制结果\nplt.figure(figsize=(12, 6))\nplt.plot(x[10:], y, label='真实值')\nplt.plot(x[10:], y_pred, label='预测值')\nplt.xlabel('时间')\nplt.ylabel('值')\nplt.legend()\nplt.show()",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "通过以上示例，我们了解了循环神经网络的基本结构和应用。在接下来的章节中，我们将深入探讨生成对抗网络的原理和应用。"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

