{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 集成学习\n",
    "\n",
    "集成学习是一种通过结合多个模型的预测结果来提高整体预测性能的方法。常见的集成学习方法包括Bagging、Boosting和Stacking等。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bagging\n",
    "\n",
    "Bagging（Bootstrap Aggregating）是一种通过对原始数据集进行多次有放回的采样，训练多个模型，并将这些模型的预测结果进行平均或投票，得到最终预测结果的方法。Bagging可以有效降低模型的方差，防止过拟合。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# 设置字体和解决负号显示问题\n",
    "plt.rcParams['font.sans-serif'] = 'Hiragino Sans GB'\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "# 生成示例数据\n",
    "X, y = make_classification(n_samples=1000, n_features=20, random_state=42)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# 拟合Bagging模型\n",
    "bagging = BaggingClassifier(estimator=DecisionTreeClassifier(), n_estimators=100, random_state=42)\n",
    "bagging.fit(X_train, y_train)\n",
    "\n",
    "# 预测并计算准确率\n",
    "y_pred = bagging.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Bagging模型的准确率: {accuracy:.2f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Boosting\n",
    "\n",
    "Boosting是一种通过逐步训练多个弱模型，每个模型都试图纠正前一个模型的错误，从而得到一个强模型的方法。常见的Boosting算法包括AdaBoost、Gradient Boosting和XGBoost等。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "# 拟合AdaBoost模型\n",
    "adaboost = AdaBoostClassifier(n_estimators=100, algorithm='SAMME', random_state=42)\n",
    "adaboost.fit(X_train, y_train)\n",
    "\n",
    "# 预测并计算准确率\n",
    "y_pred_adaboost = adaboost.predict(X_test)\n",
    "accuracy_adaboost = accuracy_score(y_test, y_pred_adaboost)\n",
    "print(f'AdaBoost模型的准确率: {accuracy_adaboost:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stacking\n",
    "\n",
    "Stacking是一种通过训练多个不同类型的基模型，并使用这些基模型的预测结果作为输入，训练一个元模型，从而得到最终预测结果的方法。Stacking可以结合不同模型的优点，提高预测性能。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# 定义基模型\n",
    "estimators = [\n",
    "    ('dt', DecisionTreeClassifier()),\n",
    "    ('ab', AdaBoostClassifier(algorithm='SAMME'))\n",
    "]\n",
    "\n",
    "# 定义元模型\n",
    "stacking = StackingClassifier(estimators=estimators, final_estimator=LogisticRegression())\n",
    "\n",
    "# 拟合Stacking模型\n",
    "stacking.fit(X_train, y_train)\n",
    "\n",
    "# 预测并计算准确率\n",
    "y_pred = stacking.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Stacking模型的准确率: {accuracy:.2f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "通过以上示例，我们了解了Bagging、Boosting和Stacking的基本原理和应用。在实际应用中，选择合适的集成学习方法可以显著提高模型的性能和鲁棒性。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
