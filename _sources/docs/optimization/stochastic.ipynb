{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# 随机优化\n\n随机优化是一种通过在搜索空间中随机选择点进行评估和优化的方法。随机优化方法通常用于解决高维和非凸优化问题。常见的随机优化方法包括随机梯度下降（SGD）、模拟退火和粒子群优化等。"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 随机梯度下降（SGD）\n\n随机梯度下降是一种常用的随机优化方法，通过每次迭代使用一个样本计算梯度，更新模型参数。SGD具有更快的收敛速度和更好的处理大规模数据集的能力。"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "import numpy as np\nimport matplotlib.pyplot as plt\n\n# 设置字体和解决负号显示问题\nplt.rcParams['font.sans-serif'] = 'Hiragino Sans GB'\nplt.rcParams['axes.unicode_minus'] = False\n\n# 定义损失函数\ndef loss_function(w):\n    return w**2 + 4*w + 4\n\n# 定义梯度\ndef gradient(w):\n    return 2*w + 4\n\n# 随机梯度下降\nw = 10  # 初始值\nlearning_rate = 0.1\niterations = 20\nw_values = [w]\nloss_values = [loss_function(w)]\nfor i in range(iterations):\n    w -= learning_rate * gradient(w)\n    w_values.append(w)\n    loss_values.append(loss_function(w))\n\n# 绘制损失函数和随机梯度下降过程\nplt.figure(figsize=(10, 5))\nplt.plot(w_values, loss_values, 'o-', label='随机梯度下降')\nplt.xlabel('参数 w')\nplt.ylabel('损失函数值')\nplt.title('随机梯度下降过程')\nplt.legend()\nplt.show()",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 模拟退火\n\n模拟退火是一种基于物理退火过程的随机优化方法，通过在搜索过程中逐渐降低“温度”，减少随机扰动，最终找到全局最优解。"
  },
 {
  "cell_type": "code",
  "metadata": {},
  "source": "def simulated_annealing(loss_function, initial_solution, max_iterations, initial_temperature, cooling_rate):\n    current_solution = initial_solution\n    current_loss = loss_function(current_solution)\n    best_solution = current_solution\n    best_loss = current_loss\n    temperature = initial_temperature\n\n    loss_history = [current_loss]\n    solution_history = [current_solution]\n\n    for iteration in range(max_iterations):\n        # 生成新解\n        new_solution = current_solution + np.random.normal(0, 1)\n        new_loss = loss_function(new_solution)\n\n        # 接受新解的概率\n        if new_loss < current_loss or np.random.rand() < np.exp((current_loss - new_loss) / temperature):\n            current_solution = new_solution\n            current_loss = new_loss\n\n            if new_loss < best_loss:\n                best_solution = new_solution\n                best_loss = new_loss\n\n        temperature *= cooling_rate\n\n        loss_history.append(current_loss)\n        solution_history.append(current_solution)\n\n    return best_solution, best_loss, solution_history, loss_history\n\n# 参数设置\ninitial_solution = 10\nmax_iterations = 100\ninitial_temperature = 10\ncooling_rate = 0.95\n\n# 执行模拟退火\nbest_solution, best_loss, solution_history, loss_history = simulated_annealing(loss_function, initial_solution, max_iterations, initial_temperature, cooling_rate)\n\n# 输出结果\nprint(f'最优解: {best_solution}')\nprint(f'最小损失: {best_loss}')\n\n# 绘制损失函数和模拟退火过程\nplt.figure(figsize=(10, 5))\nplt.plot(loss_history, label='损失值')\nplt.xlabel('迭代次数')\nplt.ylabel('损失值')\nplt.title('模拟退火过程')\nplt.legend()\nplt.show()",
  "execution_count": null,
  "outputs": []
 },
 {
  "cell_type": "markdown",
  "metadata": {},
  "source": "## 粒子群优化（PSO）\n\n粒子群优化是一种基于群体智能的随机优化方法，通过模拟群体中粒子的相互合作和竞争，找到全局最优解。"
 },
 {
  "cell_type": "code",
  "metadata": {},
  "source": "from pyswarm import pso\n\n# 定义损失函数\ndef loss_function(x):\n    return np.sum(x**2)\n\n# 定义搜索空间\nlb = [-5, -5]\nub = [5, 5]\n\n# 执行粒子群优化\nbest_solution, best_loss = pso(loss_function, lb, ub, swarmsize=100, maxiter=100)\n\n# 输出结果\nprint(f'最优解: {best_solution}')\nprint(f'最小损失: {best_loss}')",
  "execution_count": null,
  "outputs": []
 },
 {
  "cell_type": "markdown",
  "metadata": {},
  "source": "通过以上示例，我们了解了随机梯度下降、模拟退火和粒子群优化的基本原理和应用。在实际应用中，选择合适的随机优化方法可以显著提高优化效率和性能。"
 }
],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}


